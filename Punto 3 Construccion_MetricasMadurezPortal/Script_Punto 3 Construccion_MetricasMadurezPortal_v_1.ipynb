{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# PUNTO 3 – Métricas internas (NOMBRE DEL PORTAL) – \n",
    "# - Se debe usar y trabajar con salida Punto 1 archivo \n",
    "# - Normaliza tipos, limpia listas, calcula scores y niveles\n",
    "# - portal_maturity_level: bajo [0-30), medio [30-70), alto [70-100]\n",
    "# =============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 1) CONFIGURACION\n",
    "# -------------------------------------------------------------\n",
    "FILE = \"Punto1_Ayto_Barcelona_v2 DEFINITIVO.xlsx\"   # <-- tu input Punto 1\n",
    "OUT_DATA_XLSX = \"Punto3_NOMBREDELARCHIVO_USARPARARESULTADOS.xlsx\"\n",
    "OUT_DATA_CSV  = \"Punto3_NOMBREDELARCHIVO_USARPARARESULTADOS.csv\"\n",
    "OUT_SUM_XLSX  = \"Punto3_NOMBREDELARCHIVO_COMPLEMENTO.xlsx\"\n",
    "OUT_SUM_CSV   = \"Punto3_NOMBREDELARCHIVO_COMPLEMENTO.csv\"\n",
    "\n",
    "df = pd.read_excel(FILE)\n",
    "\n",
    "print(\"Dataset cargado:\", df.shape)\n",
    "print(\"Columnas detectadas:\", df.columns.tolist())\n",
    "\n",
    "TODAY = pd.to_datetime(datetime.now().date())\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 2) HELPERS\n",
    "# -------------------------------------------------------------\n",
    "def to_int01(s):\n",
    "    \"\"\"Convierte valores a 0/1 de forma robusta.\"\"\"\n",
    "    x = pd.to_numeric(s, errors=\"coerce\")\n",
    "    x = x.fillna(0)\n",
    "    return (x > 0).astype(int)\n",
    "\n",
    "def is_nonempty_text(s):\n",
    "    \"\"\"True si hay texto no vacío (evita 'nan', None, '').\"\"\"\n",
    "    if pd.isna(s):\n",
    "        return 0\n",
    "    t = str(s).strip()\n",
    "    if t == \"\" or t.lower() in {\"nan\", \"none\", \"null\"}:\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "def months_since(date):\n",
    "    \"\"\"Meses enteros desde date hasta TODAY.\"\"\"\n",
    "    if pd.isna(date):\n",
    "        return np.nan\n",
    "    return (TODAY.year - date.year) * 12 + (TODAY.month - date.month)\n",
    "\n",
    "def normalize_str(x):\n",
    "    return \"\" if pd.isna(x) else str(x).strip()\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 3) NORMALIZACIÓN FECHAS (issued / modified)\n",
    "# -------------------------------------------------------------\n",
    "for c in [\"issued\", \"modified\"]:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_datetime(df[c], errors=\"coerce\")\n",
    "\n",
    "df[\"age_months_modified\"] = df[\"modified\"].apply(months_since) if \"modified\" in df.columns else np.nan\n",
    "df[\"age_month_issued\"]    = df[\"issued\"].apply(months_since) if \"issued\" in df.columns else np.nan\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 4) FORMATOS -> listas + has_open_format\n",
    "# -------------------------------------------------------------\n",
    "OPEN_FORMATS = {\n",
    "    \"CSV\",\"JSON\",\"GEOJSON\",\"XML\",\"RDF\",\"TTL\",\"TURTLE\",\"N-TRIPLES\",\"NT\",\"JSON-LD\",\"JSONLD\"\n",
    "}\n",
    "\n",
    "def normalize_formats(fmt_original):\n",
    "    if pd.isna(fmt_original) or str(fmt_original).strip() == \"\":\n",
    "        return []\n",
    "    raw = str(fmt_original).strip().upper()\n",
    "    parts = re.split(r\"[;,|\\n\\r\\t]+\", raw)\n",
    "\n",
    "    out = []\n",
    "    for p in parts:\n",
    "        p = p.strip()\n",
    "        if not p:\n",
    "            continue\n",
    "        p = p.replace(\" \", \"\")\n",
    "        if \"JSONLD\" in p or \"JSON-LD\" in p:\n",
    "            out.append(\"JSON-LD\")\n",
    "        elif \"N-TRIPLES\" in p or p == \"NTRIPLES\":\n",
    "            out.append(\"N-TRIPLES\")\n",
    "        else:\n",
    "            out.append(p)\n",
    "\n",
    "    # unique preservando orden\n",
    "    seen, uniq = set(), []\n",
    "    for x in out:\n",
    "        if x not in seen:\n",
    "            uniq.append(x)\n",
    "            seen.add(x)\n",
    "    return uniq\n",
    "\n",
    "def split_open_nonopen(tokens):\n",
    "    open_list, nonopen_list = [], []\n",
    "    for t in tokens:\n",
    "        (open_list if t in OPEN_FORMATS else nonopen_list).append(t)\n",
    "    return open_list, nonopen_list\n",
    "\n",
    "if \"format\" not in df.columns:\n",
    "    df[\"format\"] = np.nan\n",
    "\n",
    "df[\"formats_normalized\"] = df[\"format\"].apply(normalize_formats)\n",
    "tmp = df[\"formats_normalized\"].apply(split_open_nonopen)\n",
    "df[\"open_formats_list\"] = tmp.apply(lambda x: x[0])\n",
    "df[\"non_open_formats_list\"] = tmp.apply(lambda x: x[1])\n",
    "\n",
    "df[\"open_format_count\"] = df[\"open_formats_list\"].apply(len)\n",
    "df[\"non_open_format_count\"] = df[\"non_open_formats_list\"].apply(len)\n",
    "df[\"has_open_format\"] = (df[\"open_format_count\"] > 0).astype(int)\n",
    "\n",
    "# Si Punto 1 trae has_allowed_format, lo respetamos; si no, aproximamos\n",
    "if \"has_allowed_format\" not in df.columns:\n",
    "    df[\"has_allowed_format\"] = df[\"has_open_format\"]\n",
    "df[\"has_allowed_format\"] = to_int01(df[\"has_allowed_format\"])\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 5) LICENCIA -> license_present + license_open\n",
    "# -------------------------------------------------------------\n",
    "if \"license\" not in df.columns:\n",
    "    df[\"license\"] = np.nan\n",
    "\n",
    "if \"license_present\" not in df.columns:\n",
    "    df[\"license_present\"] = df[\"license\"].notna().astype(int)\n",
    "df[\"license_present\"] = to_int01(df[\"license_present\"])\n",
    "\n",
    "if \"license_open\" not in df.columns:\n",
    "    df[\"license_open\"] = 0\n",
    "df[\"license_open\"] = to_int01(df[\"license_open\"])\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 6) DOWNLOAD URL -> download_url_present + lista unificada\n",
    "# -------------------------------------------------------------\n",
    "def parse_download_urls(x):\n",
    "    if x is None or (isinstance(x, float) and np.isnan(x)):\n",
    "        return []\n",
    "    if isinstance(x, (list, tuple, set)):\n",
    "        urls = [str(u).strip() for u in x if str(u).strip().lower().startswith(\"http\")]\n",
    "        return list(dict.fromkeys(urls))\n",
    "    s = str(x).strip()\n",
    "    if s == \"\":\n",
    "        return []\n",
    "    parts = re.split(r\"[,\\s]+\", s)\n",
    "    urls = [p for p in parts if p.lower().startswith(\"http\")]\n",
    "    return list(dict.fromkeys(urls))\n",
    "\n",
    "urls_1 = df[\"download_url\"].apply(parse_download_urls) if \"download_url\" in df.columns else pd.Series([[]]*len(df))\n",
    "urls_2 = df[\"download_urls\"].apply(parse_download_urls) if \"download_urls\" in df.columns else pd.Series([[]]*len(df))\n",
    "\n",
    "df[\"download_urls_list\"] = [\n",
    "    list(dict.fromkeys((a or []) + (b or [])))\n",
    "    for a, b in zip(urls_1.tolist(), urls_2.tolist())\n",
    "]\n",
    "df[\"download_url_present\"] = (df[\"download_urls_list\"].apply(len) > 0).astype(int)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 7) update_frequency -> update_freq_months\n",
    "# -------------------------------------------------------------\n",
    "if \"update_frequency\" not in df.columns:\n",
    "    df[\"update_frequency\"] = np.nan\n",
    "\n",
    "def map_update_frequency_to_months(freq):\n",
    "    if pd.isna(freq) or str(freq).strip() == \"\":\n",
    "        return np.nan\n",
    "\n",
    "    f = str(freq).strip().lower().replace(\"_\", \" \").replace(\"-\", \" \").strip()\n",
    "\n",
    "    # equivalencias ES/EN\n",
    "    if f in [\"monthly\", \"mensual\", \"mensualmente\"]:\n",
    "        return 1.0\n",
    "    if f in [\"weekly\", \"semanal\", \"semanalmente\"]:\n",
    "        return 0.25\n",
    "    if f in [\"daily\", \"diaria\", \"diario\"]:\n",
    "        return 1.0 / 30.0\n",
    "    if f in [\"quarterly\", \"trimestral\", \"trimestralmente\"]:\n",
    "        return 3.0\n",
    "    if f in [\"semiannual\", \"semestral\", \"semestralmente\"]:\n",
    "        return 6.0\n",
    "    if f in [\"annual\", \"anual\", \"anualmente\", \"yearly\"]:\n",
    "        return 12.0\n",
    "    if f in [\"biennial\", \"bianual\", \"bienal\", \"cada 2 años\", \"cada 2 anos\"]:\n",
    "        return 24.0\n",
    "\n",
    "    if f in [\"no definido\", \"indefinido\", \"irregular\", \"no definida\", \"unknown\", \"desconocido\"]:\n",
    "        return np.nan\n",
    "\n",
    "    return np.nan\n",
    "\n",
    "df[\"update_freq_months\"] = df[\"update_frequency\"].apply(map_update_frequency_to_months)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 8) traceable_origen = publisher + dataset_uri + identifier\n",
    "# -------------------------------------------------------------\n",
    "# Barcelona ya trae publisher/dataset_uri/identifier; si faltara alguno, se tolera.\n",
    "for col in [\"publisher\", \"dataset_uri\", \"identifier\"]:\n",
    "    if col not in df.columns:\n",
    "        df[col] = np.nan\n",
    "\n",
    "df[\"_publisher_present\"] = df[\"publisher\"].apply(is_nonempty_text).astype(int)\n",
    "df[\"_dataset_uri_present\"] = df[\"dataset_uri\"].apply(is_nonempty_text).astype(int)\n",
    "df[\"_identifier_present\"] = df[\"identifier\"].apply(is_nonempty_text).astype(int)\n",
    "\n",
    "df[\"traceable_origen\"] = (\n",
    "    (df[\"_publisher_present\"] == 1) &\n",
    "    (df[\"_dataset_uri_present\"] == 1) &\n",
    "    (df[\"_identifier_present\"] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 9) traceable_temporal = (modified + update_frequency informada)\n",
    "# -------------------------------------------------------------\n",
    "df[\"_has_age_modified\"] = df[\"age_months_modified\"].notna().astype(int)\n",
    "df[\"_has_age_issued\"] = df[\"age_month_issued\"].notna().astype(int)\n",
    "df[\"_has_update_freq\"] = df[\"update_frequency\"].notna().astype(int)\n",
    "\n",
    "df[\"traceable_temporal\"] = (\n",
    "    (df[\"_has_age_modified\"] == 1) &\n",
    "    (df[\"_has_age_issued\"] == 1) &\n",
    "    (df[\"_has_update_freq\"] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 10) traceability_score = (origen + temporal + reutilizable/doi)/3 * 100\n",
    "# -------------------------------------------------------------\n",
    "if \"has_doi\" in df.columns:\n",
    "    df[\"traceable_reutilizable\"] = to_int01(df[\"has_doi\"])\n",
    "elif \"doi\" in df.columns:\n",
    "    df[\"traceable_reutilizable\"] = df[\"doi\"].notna().astype(int)\n",
    "else:\n",
    "    df[\"traceable_reutilizable\"] = 0\n",
    "\n",
    "df[\"traceability_score\"] = (\n",
    "    (df[\"traceable_origen\"] + df[\"traceable_temporal\"] + df[\"traceable_reutilizable\"]) / 3.0 * 100\n",
    ").round(2)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 11) interoperability_semantics = (dcat + api_type + vocab + semantic_serial)/4\n",
    "# -------------------------------------------------------------\n",
    "if \"portal_supports_dcat_dcatap\" not in df.columns:\n",
    "    df[\"portal_supports_dcat_dcatap\"] = 0\n",
    "if \"api_type\" not in df.columns:\n",
    "    df[\"api_type\"] = np.nan\n",
    "if \"uses_controlled_vocab\" not in df.columns:\n",
    "    df[\"uses_controlled_vocab\"] = 0\n",
    "if \"has_semantic_serialization\" not in df.columns:\n",
    "    df[\"has_semantic_serialization\"] = 0\n",
    "\n",
    "df[\"portal_supports_dcat_dcatap\"] = to_int01(df[\"portal_supports_dcat_dcatap\"])\n",
    "df[\"uses_controlled_vocab\"] = to_int01(df[\"uses_controlled_vocab\"])\n",
    "df[\"has_semantic_serialization\"] = to_int01(df[\"has_semantic_serialization\"])\n",
    "df[\"_api_type_present\"] = df[\"api_type\"].apply(is_nonempty_text).astype(int)\n",
    "\n",
    "df[\"interoperability_semantics\"] = (\n",
    "    (df[\"portal_supports_dcat_dcatap\"] + df[\"_api_type_present\"] + df[\"uses_controlled_vocab\"] + df[\"has_semantic_serialization\"])\n",
    "    / 4.0 * 100\n",
    ").round(2)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 12) interoperability_technical = (license_open + has_open_format)/2\n",
    "# -------------------------------------------------------------\n",
    "df[\"interoperability_technical\"] = (\n",
    "    (df[\"license_open\"] + df[\"has_open_format\"]) / 2.0 * 100\n",
    ").round(2)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 13) accessibility_score = (api_rest + allowed_format + license_present + download_url_present)/4\n",
    "# -------------------------------------------------------------\n",
    "if \"portal_has_api_rest\" not in df.columns:\n",
    "    df[\"portal_has_api_rest\"] = 0\n",
    "df[\"portal_has_api_rest\"] = to_int01(df[\"portal_has_api_rest\"])\n",
    "\n",
    "df[\"accessibility_score\"] = (\n",
    "    (df[\"portal_has_api_rest\"] + df[\"has_allowed_format\"] + df[\"license_present\"] + df[\"download_url_present\"])\n",
    "    / 4.0 * 100\n",
    ").round(2)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 14) quality_score = (has_data_dictionary + description_present)/2\n",
    "# -------------------------------------------------------------\n",
    "if \"has_data_dictionary\" not in df.columns:\n",
    "    df[\"has_data_dictionary\"] = 0\n",
    "df[\"has_data_dictionary\"] = to_int01(df[\"has_data_dictionary\"])\n",
    "\n",
    "if \"description\" not in df.columns:\n",
    "    df[\"description\"] = np.nan\n",
    "df[\"_description_present\"] = df[\"description\"].apply(is_nonempty_text).astype(int)\n",
    "\n",
    "df[\"quality_score\"] = (\n",
    "    (df[\"has_data_dictionary\"] + df[\"_description_present\"]) / 2.0 * 100\n",
    ").round(2)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 15) portal_maturity = promedio de 5 scores\n",
    "# -------------------------------------------------------------\n",
    "df[\"portal_maturity\"] = (\n",
    "    (df[\"accessibility_score\"] + df[\"interoperability_semantics\"] + df[\"interoperability_technical\"] + df[\"traceability_score\"] + df[\"quality_score\"])\n",
    "    / 5.0\n",
    ").round(2)\n",
    "\n",
    "# NUEVOS CORTES \n",
    "df[\"portal_maturity_level\"] = pd.cut(\n",
    "    df[\"portal_maturity\"],\n",
    "    bins=[-0.1, 30, 60, 100],\n",
    "    labels=[\"bajo\", \"medio\", \"alto\"]\n",
    ").astype(str)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 16) LIMPIEZA columnas viejas/auxiliares\n",
    "# -------------------------------------------------------------\n",
    "COLUMNS_TO_DROP = [\n",
    "    \"frequency_documented\",\n",
    "    \"selected_for_analysis\",\n",
    "    \"age_since_issued_months\",\n",
    "    \"months_since_modified\",\n",
    "    \"age_reference_date\",\n",
    "    \"months_since_reference\",\n",
    "    \"stale_12m\",\n",
    "    \"license_class\",\n",
    "    \"license_family\",\n",
    "    \"update_cadence_group\",\n",
    "    \"updates_slower_than_month\",\n",
    "    \"api_score\",\n",
    "    \"freq_score\",\n",
    "    \"operational_traceability\",\n",
    "    \"update_transparency_score\",\n",
    "    \"license_openness_score\",\n",
    "    \"format_openness_score\",\n",
    "    \"metadata_completeness\",\n",
    "    \"maturity_index\",\n",
    "    \"maturity_level\",\n",
    "    \"format_openness_score\",\n",
    "]\n",
    "\n",
    "df.drop(columns=[c for c in COLUMNS_TO_DROP if c in df.columns], inplace=True)\n",
    "\n",
    "# columnas auxiliares internas que empiezan por \"_\"\n",
    "aux_cols = [c for c in df.columns if c.startswith(\"_\")]\n",
    "df.drop(columns=aux_cols, inplace=True, errors=\"ignore\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 17) EXPORT DATASET-LEVEL\n",
    "# -------------------------------------------------------------\n",
    "df.to_excel(OUT_DATA_XLSX, index=False)\n",
    "df.to_csv(OUT_DATA_CSV, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"\\nDataset-level V2 LIMPIO generado:\")\n",
    "print(\" -\", OUT_DATA_XLSX)\n",
    "print(\" -\", OUT_DATA_CSV)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 18) RESUMEN ÚNICO PARA GRÁFICAS (1 tabla)\n",
    "# metric | category | count\n",
    "# -------------------------------------------------------------\n",
    "rows = []\n",
    "\n",
    "# A) Distribución niveles de madurez (según cortes nuevos 0-30-60-100)\n",
    "for k, v in df[\"portal_maturity_level\"].value_counts(dropna=False).items():\n",
    "    rows.append({\"metric\": \"PORTAL_MATURITY_LEVEL\", \"category\": str(k), \"count\": int(v)})\n",
    "\n",
    "# B) Trazabilidad (componentes)\n",
    "rows.append({\"metric\": \"TRACEABLE_ORIGEN\", \"category\": \"si\", \"count\": int((df[\"traceable_origen\"] == 1).sum())})\n",
    "rows.append({\"metric\": \"TRACEABLE_ORIGEN\", \"category\": \"no\", \"count\": int((df[\"traceable_origen\"] == 0).sum())})\n",
    "\n",
    "rows.append({\"metric\": \"TRACEABLE_TEMPORAL\", \"category\": \"si\", \"count\": int((df[\"traceable_temporal\"] == 1).sum())})\n",
    "rows.append({\"metric\": \"TRACEABLE_TEMPORAL\", \"category\": \"no\", \"count\": int((df[\"traceable_temporal\"] == 0).sum())})\n",
    "\n",
    "rows.append({\"metric\": \"TRACEABLE_REUTILIZABLE_DOI\", \"category\": \"si\", \"count\": int((df[\"traceable_reutilizable\"] == 1).sum())})\n",
    "rows.append({\"metric\": \"TRACEABLE_REUTILIZABLE_DOI\", \"category\": \"no\", \"count\": int((df[\"traceable_reutilizable\"] == 0).sum())})\n",
    "\n",
    "# Traceability score bins (0/33/66/100)\n",
    "df[\"traceability_score_bin\"] = pd.cut(\n",
    "    df[\"traceability_score\"],\n",
    "    bins=[-0.1, 1, 34, 67, 100.1],\n",
    "    labels=[\"0\", \"33\", \"66\", \"100\"]\n",
    ").astype(str)\n",
    "\n",
    "for k, v in df[\"traceability_score_bin\"].value_counts(dropna=False).items():\n",
    "    rows.append({\"metric\": \"TRACEABILITY_SCORE_BIN\", \"category\": str(k), \"count\": int(v)})\n",
    "\n",
    "# C) Bins para dimensiones (usando tus cortes 0-30-60-100)\n",
    "def level_0_30_60(x):\n",
    "    return pd.cut(x, bins=[-0.1, 30, 60, 100], labels=[\"bajo\", \"medio\", \"alto\"]).astype(str)\n",
    "\n",
    "for metric_col, metric_name in [\n",
    "    (\"interoperability_semantics\", \"INTEROP_SEMANTICS_BIN\"),\n",
    "    (\"interoperability_technical\", \"INTEROP_TECHNICAL_BIN\"),\n",
    "    (\"accessibility_score\", \"ACCESSIBILITY_SCORE_BIN\"),\n",
    "    (\"quality_score\", \"QUALITY_SCORE_BIN\"),\n",
    "]:\n",
    "    b = level_0_30_60(pd.to_numeric(df[metric_col], errors=\"coerce\"))\n",
    "    for k, v in b.value_counts(dropna=False).items():\n",
    "        rows.append({\"metric\": metric_name, \"category\": str(k), \"count\": int(v)})\n",
    "\n",
    "summary = pd.DataFrame(rows)\n",
    "\n",
    "summary.to_excel(OUT_SUM_XLSX, index=False)\n",
    "summary.to_csv(OUT_SUM_CSV, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"\\nResumen único para gráficas V2 generado:\")\n",
    "print(\" -\", OUT_SUM_XLSX)\n",
    "print(\" -\", OUT_SUM_CSV)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
