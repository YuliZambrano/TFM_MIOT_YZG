{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e15ce32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Castilla y León – datasets: 419\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# PORTALNOMBRE – OPENDATASOFT   EJEMPLO PORTAL:\n",
    "\n",
    "# ===============================\n",
    "\n",
    "import re\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone\n",
    "import unicodedata\n",
    "\n",
    "PORTAL = \"PORTAL\"\n",
    "API_TYPE = \"OPENDATASOFT\"     #TIPO DE API\n",
    "API_BASE = \"https://analisis.datosabiertos.jcyl.es/api/explore/v2.1\"      #URL DE API\n",
    "SITE_BASE = \"https://analisis.datosabiertos.jcyl.es\"                     #URL ENDPOINT DE API   \n",
    "\n",
    "TIMEOUT = 45\n",
    "SLEEP = 0.05\n",
    "LIMIT = 100                                         \n",
    "MAX_DATASETS = 600              # PUEDE CAMBIAR EL LIMITE DE DATASET\n",
    "\n",
    "UA_HEADERS = {\"User-Agent\": \"TFM-IIP-Metadata-Extractor/1.0\"}\n",
    "\n",
    "# ---------------- Helpers ----------------\n",
    "\n",
    "def safe_get(url, params=None):\n",
    "    r = requests.get(url, params=params, headers=UA_HEADERS, timeout=TIMEOUT)\n",
    "    r.raise_for_status()\n",
    "    return r\n",
    "\n",
    "def pick_first(*vals, default=\"\"):\n",
    "    for v in vals:\n",
    "        if isinstance(v, str) and v.strip():\n",
    "            return v.strip()\n",
    "    return default\n",
    "\n",
    "def parse_dt(s):\n",
    "    if not s:\n",
    "        return None\n",
    "    try:\n",
    "        dt = datetime.fromisoformat(str(s).replace(\"Z\", \"+00:00\"))\n",
    "        if not dt.tzinfo:\n",
    "            dt = dt.replace(tzinfo=timezone.utc)\n",
    "        return dt\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def meets_age_criterion(issued_dt, years=1):\n",
    "    if not issued_dt:\n",
    "        return False\n",
    "    return (datetime.now(timezone.utc) - issued_dt).days >= 365 * years\n",
    "\n",
    "def head_or_get_public(url):\n",
    "    if not url or not url.startswith(\"http\"):\n",
    "        return False\n",
    "    try:\n",
    "        h = requests.head(url, headers=UA_HEADERS, timeout=TIMEOUT, allow_redirects=True)\n",
    "        if h.status_code in (403, 405):\n",
    "            g = requests.get(url, headers=UA_HEADERS, timeout=TIMEOUT, allow_redirects=True)\n",
    "            return 200 <= g.status_code < 400\n",
    "        return 200 <= h.status_code < 400\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def is_open_license(text):\n",
    "    s = (text or \"\").lower()\n",
    "    if not s:\n",
    "        return 0\n",
    "    if any(x in s for x in [\"noncommercial\", \"no comercial\", \"nd\", \"noderivatives\"]):\n",
    "        return 0\n",
    "    if \"cc by\" in s or \"cc0\" in s or \"public domain\" in s or \"aviso legal\" in s:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def license_bucket_p1(text):\n",
    "    if not text:\n",
    "        return \"Vacío legal\"\n",
    "    return \"Apertura total\" if is_open_license(text) else \"Restringida\"\n",
    "\n",
    "# ---------------- Fetch ODS ----------------\n",
    "\n",
    "def fetch_datasets():\n",
    "    url = f\"{API_BASE}/catalog/datasets\"\n",
    "    offset = 0\n",
    "    out = []\n",
    "\n",
    "    while True:\n",
    "        js = safe_get(url, params={\"limit\": LIMIT, \"offset\": offset}).json()\n",
    "        results = js.get(\"results\", [])\n",
    "        if not results:\n",
    "            break\n",
    "        out.extend(results)\n",
    "        offset += LIMIT\n",
    "        time.sleep(SLEEP)\n",
    "        if MAX_DATASETS and len(out) >= MAX_DATASETS:\n",
    "            return out[:MAX_DATASETS]\n",
    "    return out\n",
    "\n",
    "def fetch_dataset_detail(dataset_id):\n",
    "    return safe_get(f\"{API_BASE}/catalog/datasets/{dataset_id}\").json()\n",
    "\n",
    "# ---------------- MAIN ----------------\n",
    "\n",
    "def main():\n",
    "    rows = []\n",
    "    items = fetch_datasets()\n",
    "\n",
    "    for it in items:\n",
    "        dataset_id = it.get(\"dataset_id\")\n",
    "        if not dataset_id:\n",
    "            continue\n",
    "\n",
    "        detail = fetch_dataset_detail(dataset_id)\n",
    "        metas = detail.get(\"metas\", {})\n",
    "        metas_default = metas.get(\"default\", {})\n",
    "        metas_dcat = metas.get(\"dcat\", {})\n",
    "\n",
    "        title = pick_first(metas_default.get(\"title\"), dataset_id)\n",
    "        notes = pick_first(metas_default.get(\"description\"))\n",
    "\n",
    "        publisher = pick_first(\n",
    "            metas_default.get(\"publisher\"),\n",
    "            metas_dcat.get(\"publisher\"),\n",
    "            default=\"Junta de Castilla y León\"\n",
    "        )\n",
    "\n",
    "        license_text = pick_first(\n",
    "            metas_default.get(\"license\"),\n",
    "            metas_dcat.get(\"license\")\n",
    "        )\n",
    "\n",
    "        issued = pick_first(\n",
    "            metas_default.get(\"metadata_processed\"),\n",
    "            metas_default.get(\"created\")\n",
    "        )\n",
    "\n",
    "        modified = pick_first(\n",
    "            metas_default.get(\"modified\"),\n",
    "            metas_default.get(\"data_processed\")\n",
    "        )\n",
    "\n",
    "        issued_dt = parse_dt(issued)\n",
    "\n",
    "        update_frequency = pick_first(metas_default.get(\"accrualperiodicity\"))\n",
    "        frequency_documented = bool(update_frequency)\n",
    "\n",
    "        dataset_uri = f\"{SITE_BASE}/explore/dataset/{dataset_id}/\"\n",
    "        download_url = f\"{SITE_BASE}/explore/dataset/{dataset_id}/download/?format=csv\"\n",
    "        \n",
    "        \n",
    "        dataset_url_ok = head_or_get_public(dataset_uri)\n",
    "        download_url_ok = head_or_get_public(download_url)\n",
    "        public_access_ok = 1 if download_url_ok else 0\n",
    "\n",
    "        rdf_meta_url = f\"{SITE_BASE}/api/v2/catalog/datasets/{dataset_id}?format=dcat\"\n",
    "        metadata_rdf_available = 1 if head_or_get_public(rdf_meta_url) else 0\n",
    "\n",
    "# SE PUEDEN AGREGAR O QUITAR COLUMNAS DE RESULTADOS SIEMPRE QUE LAS DEFINAS\n",
    "        rows.append({\n",
    "            \"portal\": PORTAL,\n",
    "            \"api_type\": API_TYPE,\n",
    "            \"portal_has_api_rest\": 1,\n",
    "            \"portal_supports_dcat_dcatap\": 1,\n",
    "\n",
    "            \"identifier\": \"\",\n",
    "            \"doi\": \"\",\n",
    "            \"has_doi\": 0,\n",
    "\n",
    "            \"publisher\": publisher,\n",
    "\n",
    "            \"download_url\": download_url,\n",
    "            \"download_urls\": download_url,\n",
    "\n",
    "            \"license\": license_text,\n",
    "            \"license_present\": bool(license_text),\n",
    "            \"license_open\": is_open_license(license_text),\n",
    "            \"license_bucket\": license_bucket_p1(license_text),\n",
    "\n",
    "            \"dataset_id\": dataset_id,\n",
    "            \"dataset_uri\": dataset_uri,\n",
    "\n",
    "            \"title\": title,\n",
    "            \"description\": notes,\n",
    "            \"category\": \"\",\n",
    "            \"category_source\": \"\",\n",
    "            \"uses_controlled_vocab\": 0,\n",
    "            \"controlled_vocab_source\": \"\",\n",
    "\n",
    "            \"issued\": issued,\n",
    "            \"modified\": modified,\n",
    "            \"meets_age_criterion\": meets_age_criterion(issued_dt),\n",
    "\n",
    "            \"format\": \"CSV\",\n",
    "            \"n_formats\": 1,\n",
    "            \"metadata_rdf_available\": metadata_rdf_available,\n",
    "\n",
    "            \"has_allowed_format\": 1,\n",
    "            \"has_semantic_serialization\": metadata_rdf_available,\n",
    "            \"has_data_dictionary\": 0,\n",
    "            \"update_frequency\": update_frequency,\n",
    "            \"frequency_documented\": frequency_documented,\n",
    "            \"public_access_ok\": public_access_ok,\n",
    "        })\n",
    "  # SE PUEDEN CAMBIAR LOS NOMBRES DE LOS ARCHIVOS RESULTADOS CSV Y XLSX  \n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(\"Punto1_NOMBREPORTAL.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "    df.to_excel(\"Punto1_NOMBREPORTAL.xlsx\", index=False)\n",
    "\n",
    "    print(f\"✅ {PORTAL} – datasets: {len(df)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd0d82c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
