{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae8efbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# PUNTO 4 – Dashboard y Resultados de metricas\n",
    "\n",
    "#   1) Trazabilidad temporal (age_month_issued / age_months_modified)  \n",
    "#   2) Traceability componentes (conteo) + desglose agregado (normalizado 100)\n",
    "#   3) Update frequency (vacíos -> \"No definido\") con conteo + %\n",
    "#   4) Traceability_score (0/33/66/100) -> barras (NO hist) + interpretación clara\n",
    "#   5) interoperability_semantics (distribución) + componentes + desglose\n",
    "#   6) interoperability_technical (distribución) + componentes + desglose\n",
    "#   7) accessibility_score (distribución) + componentes + desglose\n",
    "#   8) quality_score (distribución) + componentes (CONTEO) + desglose\n",
    "#   9) Índice global (portal_maturity) -> scorecard + niveles (conteo + %)\n",
    "# =============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import ast\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "TODAY = pd.to_datetime(datetime.now().date())\n",
    "\n",
    "# =============================\n",
    "# INPUTS / OUTPUT\n",
    "# =============================\n",
    "DATASET_XLSX = \"Punto3_NOMBREDELARCHIVO_USARPARARESULTADOS.xlsx\"          # ESTOS NOMBRES SE PUEDEN MODIFICAR\n",
    "DATASET_CSV  = \"Punto3_NOMBREDELARCHIVO_USARPARARESULTADOS.csv\"           # ESTOS NOMBRES SE PUEDEN MODIFICAR\n",
    "OUT_HTML = \"Punto4_RESULTADOS.html\"                                        # ESTOS NOMBRES SE PUEDEN MODIFICAR\n",
    "\n",
    "# -----------------------------\n",
    "# LOAD\n",
    "# -----------------------------\n",
    "try:\n",
    "    df = pd.read_excel(DATASET_XLSX)\n",
    "except:\n",
    "    df = pd.read_csv(DATASET_CSV)\n",
    "\n",
    "# -----------------------------\n",
    "# Normalizaciones base\n",
    "# -----------------------------\n",
    "for c in [\"issued\", \"modified\"]:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_datetime(df[c], errors=\"coerce\")\n",
    "\n",
    "# Si no existe portal (caso Barcelona), lo fija\n",
    "if \"portal\" not in df.columns:\n",
    "    df[\"portal\"] = \"Barcelona\"\n",
    "\n",
    "# Asegurar numéricos para flags principales si existen\n",
    "for c in [\n",
    "    \"portal_has_api_rest\",\n",
    "    \"license_present\",\"license_open\",\n",
    "    \"has_data_dictionary\",\"has_semantic_serialization\",\n",
    "    \"portal_supports_dcat_dcatap\",\"has_allowed_format\",\n",
    "    \"has_open_format\",\"uses_controlled_vocab\",\n",
    "    \"download_url_present\",\n",
    "    \"traceable_origen\",\"traceable_temporal\",\"traceable_reutilizable\",\n",
    "]:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\").fillna(0)\n",
    "\n",
    "# -----------------------------\n",
    "# parse de listas de formatos (para gráficas 1 y 2)\n",
    "# -----------------------------\n",
    "def parse_list_cell(x):\n",
    "    if isinstance(x, (list, tuple, set)):\n",
    "        return list(x)\n",
    "    if pd.isna(x):\n",
    "        return []\n",
    "    s = str(x).strip()\n",
    "    if s == \"\":\n",
    "        return []\n",
    "    try:\n",
    "        v = ast.literal_eval(s)\n",
    "        if isinstance(v, list):\n",
    "            return v\n",
    "    except:\n",
    "        pass\n",
    "    return [t.strip() for t in re.split(r\"[;,|\\s]+\", s) if t.strip()]\n",
    "\n",
    "if \"open_formats_list\" not in df.columns:\n",
    "    df[\"open_formats_list\"] = [[] for _ in range(len(df))]\n",
    "if \"non_open_formats_list\" not in df.columns:\n",
    "    df[\"non_open_formats_list\"] = [[] for _ in range(len(df))]\n",
    "\n",
    "df[\"open_formats_list_parsed\"] = df[\"open_formats_list\"].apply(parse_list_cell)\n",
    "df[\"non_open_formats_list_parsed\"] = df[\"non_open_formats_list\"].apply(parse_list_cell)\n",
    "\n",
    "# -----------------------------\n",
    "# Estilo global (márgenes + altura consistente)\n",
    "# -----------------------------\n",
    "def polish(fig, height=460):\n",
    "    fig.update_layout(\n",
    "        height=height,\n",
    "        margin=dict(l=60, r=30, t=70, b=80),\n",
    "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"left\", x=0),\n",
    "        font=dict(size=14),\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "# =============================================================\n",
    "# Paletas / Colores\n",
    "# =============================================================\n",
    "COLORS = {\n",
    "    \"abierto\": \"#1f77b4\",      # Azul\n",
    "    \"cerrado\": \"#ff7f0e\",      # Naranja\n",
    "    \"restringido\": \"#d62728\",  # Rojo\n",
    "    \"vacio\": \"#7f7f7f\"         # Gris\n",
    "}\n",
    "\n",
    "COMP_COLORS = {\n",
    "    \"Origen\": \"#1f77b4\",\n",
    "    \"Temporal\": \"#2ca02c\",\n",
    "    \"Reutilizable (DOI)\": \"#d62728\",\n",
    "    \"DOI/Reutilizable\": \"#d62728\",\n",
    "\n",
    "    \"DCAT/DCAT-AP\": \"#1f77b4\",\n",
    "    \"API type presente\": \"#9467bd\",\n",
    "    \"Vocabulario controlado\": \"#2ca02c\",\n",
    "    \"Serialización semántica\": \"#ff7f0e\",\n",
    "\n",
    "    \"Licencia abierta\": \"#1f77b4\",\n",
    "    \"Formato abierto\": \"#ff7f0e\",\n",
    "\n",
    "    \"API REST\": \"#1f77b4\",\n",
    "    \"Formato permitido\": \"#ff7f0e\",\n",
    "    \"Licencia presente\": \"#2ca02c\",\n",
    "    \"URL descarga\": \"#d62728\",\n",
    "\n",
    "    \"Diccionario de datos\": \"#1f77b4\",\n",
    "    \"Descripción presente\": \"#ff7f0e\",\n",
    "}\n",
    "\n",
    "# =============================================================\n",
    "# Helpers (gráficas)\n",
    "# =============================================================\n",
    "def stacked_breakdown(labels, values, title):\n",
    "    # values en % (0-100) -> normaliza a 100\n",
    "    vals = np.array(values, dtype=float)\n",
    "    tot = vals.sum()\n",
    "    if tot > 0:\n",
    "        vals = vals / tot * 100.0\n",
    "\n",
    "    fig = go.Figure()\n",
    "    left = 0.0\n",
    "    for lab, v in zip(labels, vals):\n",
    "        fig.add_trace(go.Bar(\n",
    "            x=[v], y=[\"\"],\n",
    "            orientation=\"h\",\n",
    "            name=lab,\n",
    "            marker=dict(color=COMP_COLORS.get(lab, None)),\n",
    "            text=[f\"{v:.1f}%\"],\n",
    "            textposition=\"inside\",\n",
    "            insidetextanchor=\"middle\",\n",
    "            base=left\n",
    "        ))\n",
    "        left += v\n",
    "\n",
    "    fig.update_layout(\n",
    "        barmode=\"stack\",\n",
    "        xaxis=dict(range=[0, 100], title=\"Contribución (%)\"),\n",
    "        yaxis=dict(showticklabels=False),\n",
    "        title=title\n",
    "    )\n",
    "    return polish(fig, height=300)\n",
    "\n",
    "def hist_score(data, col, title, xlabel=\"Score (0–100)\", nbins=20):\n",
    "    tmp = data.copy()\n",
    "    tmp[col] = pd.to_numeric(tmp[col], errors=\"coerce\")\n",
    "    tmp = tmp.dropna(subset=[col])\n",
    "    fig = px.histogram(tmp, x=col, nbins=nbins, title=title, labels={col: xlabel, \"count\":\"Nº de datasets\"})\n",
    "    fig.update_layout(xaxis_range=[0, 100])\n",
    "    fig.update_yaxes(title_text=\"Nº de datasets\")\n",
    "    return polish(fig, height=420)\n",
    "\n",
    "def bar_components_pct(labels, values, title):\n",
    "    comp = pd.DataFrame({\"Componente\": labels, \"Valor\": values})\n",
    "    fig = px.bar(\n",
    "        comp, x=\"Componente\", y=\"Valor\",\n",
    "        text=comp[\"Valor\"].round(1),\n",
    "        title=title,\n",
    "        labels={\"Valor\":\"% de datasets\"}\n",
    "    )\n",
    "    fig.update_traces(\n",
    "        textposition=\"outside\", cliponaxis=False,\n",
    "        marker_color=[COMP_COLORS.get(x, \"#1f77b4\") for x in comp[\"Componente\"]]\n",
    "    )\n",
    "    fig.update_layout(yaxis_range=[0, 105], xaxis_tickangle=-20)\n",
    "    return polish(fig, height=420)\n",
    "\n",
    "def bar_components_count(labels, counts, title):\n",
    "    comp = pd.DataFrame({\"Componente\": labels, \"Datasets\": counts})\n",
    "    fig = px.bar(\n",
    "        comp, x=\"Componente\", y=\"Datasets\",\n",
    "        text=\"Datasets\",\n",
    "        title=title,\n",
    "        labels={\"Datasets\":\"Nº de datasets\"}\n",
    "    )\n",
    "    fig.update_traces(\n",
    "        textposition=\"outside\", cliponaxis=False,\n",
    "        marker_color=[COMP_COLORS.get(x, \"#1f77b4\") for x in comp[\"Componente\"]]\n",
    "    )\n",
    "    fig.update_layout(xaxis_tickangle=-20)\n",
    "    fig.update_yaxes(title_text=\"Nº de datasets\")\n",
    "    return polish(fig, height=420)\n",
    "\n",
    "def scorecard(scores_dict, title):\n",
    "    tmp = pd.DataFrame({\"Métrica\": list(scores_dict.keys()), \"Score\": list(scores_dict.values())})\n",
    "    tmp[\"Score\"] = pd.to_numeric(tmp[\"Score\"], errors=\"coerce\")\n",
    "    tmp = tmp.sort_values(\"Score\", ascending=False)\n",
    "\n",
    "    fig = px.bar(\n",
    "        tmp, x=\"Métrica\", y=\"Score\",\n",
    "        text=tmp[\"Score\"].round(1),\n",
    "        title=title,\n",
    "        labels={\"Score\":\"Promedio (0–100)\"}\n",
    "    )\n",
    "    fig.update_traces(textposition=\"outside\", cliponaxis=False)\n",
    "    fig.update_layout(yaxis_range=[0, 105], xaxis_tickangle=-20)\n",
    "    return polish(fig, height=460)\n",
    "\n",
    "def traceability_score_bars(g, portal_name):\n",
    "    \"\"\"\n",
    "    Traceability_score viene de Punto 3 como:\n",
    "        ((traceable_origen + traceable_temporal + traceable_reutilizable)/3)*100\n",
    "    => valores esperados: 0, 33.33, 66.67, 100 (aprox)\n",
    "    Lo hacemos amigable con barras por nivel.\n",
    "    \"\"\"\n",
    "    s = pd.to_numeric(g[\"traceability_score\"], errors=\"coerce\").dropna()\n",
    "\n",
    "    def snap(v):\n",
    "        levels = np.array([0, 33.33, 66.67, 100.0])\n",
    "        return float(levels[np.argmin(np.abs(levels - v))])\n",
    "\n",
    "    snapped = s.apply(snap)\n",
    "    counts = snapped.value_counts().reindex([0.0, 33.33, 66.67, 100.0]).fillna(0).astype(int)\n",
    "\n",
    "    dfb = pd.DataFrame({\n",
    "        \"Nivel\": [\"0\", \"33\", \"66\", \"100\"],\n",
    "        \"Datasets\": counts.values\n",
    "    })\n",
    "\n",
    "    fig = px.bar(\n",
    "        dfb, x=\"Nivel\", y=\"Datasets\",\n",
    "        text=\"Datasets\",\n",
    "        title=f\"Traceability score (0–100) – distribución por niveles | {portal_name}\",\n",
    "        labels={\"Datasets\":\"Nº de datasets\"}\n",
    "    )\n",
    "    level_colors = [\"#d62728\", \"#ff7f0e\", \"#2ca02c\", \"#1f77b4\"]\n",
    "    fig.update_traces(marker_color=level_colors, textposition=\"outside\", cliponaxis=False)\n",
    "    fig.update_yaxes(title_text=\"Nº de datasets\")\n",
    "    fig.update_layout(xaxis_title=\"Score (0–100)\")\n",
    "    return polish(fig, height=420)\n",
    "\n",
    "# =============================================================\n",
    "# 1) Interoperabilidad técnica – Tipos de formatos detectados \n",
    "# =============================================================\n",
    "OPEN_FORMATS = [\"CSV\",\"JSON\",\"GEOJSON\",\"XML\",\"RDF\",\"TTL\",\"TURTLE\",\"N-TRIPLES\",\"NT\",\"JSON-LD\",\"JSONLD\"]\n",
    "\n",
    "open_counts = []\n",
    "for f in OPEN_FORMATS:\n",
    "    cnt = int(df[\"open_formats_list_parsed\"].apply(lambda lst: 1 if f in lst else 0).sum())\n",
    "    if cnt > 0:\n",
    "        open_counts.append({\"Formato\": f, \"Datasets\": cnt})\n",
    "open_counts_df = pd.DataFrame(open_counts)\n",
    "\n",
    "others_count = int(df[\"non_open_formats_list_parsed\"].apply(lambda lst: 1 if len(lst) > 0 else 0).sum())\n",
    "others_df = pd.DataFrame([{\"Formato\": \"Otros formatos (cerrados)\", \"Datasets\": others_count}])\n",
    "\n",
    "fmt_bar_df = pd.concat([open_counts_df, others_df], ignore_index=True)\n",
    "fmt_bar_df = fmt_bar_df.sort_values(\"Datasets\", ascending=False)\n",
    "\n",
    "fmt_bar_df[\"Tipo\"] = fmt_bar_df[\"Formato\"].apply(lambda x: \"Abierto\" if x in OPEN_FORMATS else \"Cerrado\")\n",
    "\n",
    "fig_fmt_types = px.bar(\n",
    "    fmt_bar_df,\n",
    "    x=\"Formato\", y=\"Datasets\",\n",
    "    text=\"Datasets\",\n",
    "    title=\"Clasificación de formatos para interoperabilidad técnica\",\n",
    "    labels={\"Datasets\": \"Nº de datasets\"},\n",
    "    color=\"Tipo\",\n",
    "    color_discrete_map={\"Abierto\": COLORS[\"abierto\"], \"Cerrado\": COLORS[\"cerrado\"]}\n",
    ")\n",
    "fig_fmt_types.update_traces(textposition=\"outside\", cliponaxis=False)\n",
    "fig_fmt_types.update_layout(xaxis=dict(tickangle=-25, categoryorder=\"total descending\"))\n",
    "polish(fig_fmt_types, height=500)\n",
    "\n",
    "caption_fmt_types = (\n",
    "    \"<b>Interpretación.</b> Cada barra de formato abierto indica cuántos datasets del portal lo ofrecen. \"\n",
    "    \"La barra <i>Otros formatos (cerrados)</i> agrupa datasets con al menos un formato propietario o no estándar.\"\n",
    ")\n",
    "\n",
    "# =============================================================\n",
    "# 2) Interoperabilidad en formatos – porcentaje \n",
    "# =============================================================\n",
    "if \"open_format_count\" not in df.columns or df[\"open_format_count\"].isna().all():\n",
    "    df[\"open_format_count\"] = df[\"open_formats_list_parsed\"].apply(len)\n",
    "if \"non_open_format_count\" not in df.columns or df[\"non_open_format_count\"].isna().all():\n",
    "    df[\"non_open_format_count\"] = df[\"non_open_formats_list_parsed\"].apply(len)\n",
    "\n",
    "open_total = float(df[\"open_format_count\"].fillna(0).sum())\n",
    "non_open_total = float(df[\"non_open_format_count\"].fillna(0).sum())\n",
    "den = (open_total + non_open_total) if (open_total + non_open_total) > 0 else 1\n",
    "\n",
    "fmt_pct = pd.DataFrame({\n",
    "    \"Clasificación\": [\"Abiertos\", \"Cerrados/Propietarios\"],\n",
    "    \"Porcentaje\": [100 * open_total/den, 100 * non_open_total/den]\n",
    "})\n",
    "\n",
    "fig_fmt_pct = px.bar(\n",
    "    fmt_pct,\n",
    "    x=\"Clasificación\", y=\"Porcentaje\",\n",
    "    text=fmt_pct[\"Porcentaje\"].round(1),\n",
    "    title=\"Distribución porcentual de formatos (dimensión técnica)\",\n",
    "    labels={\"Porcentaje\":\"Porcentaje (%)\"},\n",
    "    color=\"Clasificación\",\n",
    "    color_discrete_map={\"Abiertos\": COLORS[\"abierto\"], \"Cerrados/Propietarios\": COLORS[\"cerrado\"]}\n",
    ")\n",
    "fig_fmt_pct.update_traces(textposition=\"outside\", cliponaxis=False)\n",
    "fig_fmt_pct.update_layout(yaxis_range=[0, 105])\n",
    "polish(fig_fmt_pct, height=420)\n",
    "\n",
    "caption_fmt_pct = (\n",
    "    \"<b>Interpretación.</b> Proporción calculada sobre el total de formatos reportados en los metadatos \"\n",
    "    \"(sumatoria de formatos abiertos y cerrados por dataset).\"\n",
    ")\n",
    "\n",
    "# =============================================================\n",
    "# 3) Licenciamiento permitido – 3 categorías\n",
    "# =============================================================\n",
    "if \"license\" not in df.columns:\n",
    "    df[\"license\"] = np.nan\n",
    "if \"license_present\" not in df.columns:\n",
    "    df[\"license_present\"] = df[\"license\"].notna().astype(int)\n",
    "if \"license_open\" not in df.columns:\n",
    "    df[\"license_open\"] = 0\n",
    "\n",
    "def license_bucket(row):\n",
    "    lic = str(row.get(\"license\",\"\") if pd.notna(row.get(\"license\",np.nan)) else \"\").lower()\n",
    "    present = int(pd.to_numeric(row.get(\"license_present\", 0), errors=\"coerce\") or 0)\n",
    "    open_flag = int(pd.to_numeric(row.get(\"license_open\", 0), errors=\"coerce\") or 0)\n",
    "\n",
    "    # 1) Vacío legal / no definido\n",
    "    if (\n",
    "        present == 0\n",
    "        or lic.strip() == \"\"\n",
    "        or \"no definido\" in lic\n",
    "        or \"sin definir\" in lic\n",
    "        or \"consultar\" in lic\n",
    "        or \"consulte\" in lic\n",
    "        or \"consejer\" in lic\n",
    "        or \"permiso\" in lic\n",
    "        or \"autoriz\" in lic\n",
    "    ):\n",
    "        return \"Vacío legal\"\n",
    "\n",
    "    # 2) Restricciones explícitas (PRIORIDAD MÁXIMA)\n",
    "    if (\n",
    "        \"noncommercial\" in lic\n",
    "        or \"no comercial\" in lic\n",
    "        or \"no-comercial\" in lic\n",
    "        or re.search(r\"\\bby[-\\s]?nc\\b\", lic)\n",
    "        or \"noderivatives\" in lic\n",
    "        or \"sin deriv\" in lic\n",
    "        or re.search(r\"\\bby[-\\s]?nd\\b\", lic)\n",
    "    ):\n",
    "        return \"Restringida\"\n",
    "\n",
    "    # 3) Aviso legal estándar (abierta)\n",
    "    if \"avisolegal\" in lic or \"/aviso-legal\" in lic or \"aviso legal\" in lic:\n",
    "        return \"Apertura total\"\n",
    "\n",
    "    # 4) Creative Commons realmente abiertas (sin NC / ND)\n",
    "    if (\n",
    "        \"cc0\" in lic\n",
    "        or (\n",
    "            ((\"creative commons\" in lic) or re.search(r\"\\bcc\\b\", lic))\n",
    "            and (\"nc\" not in lic and \"nd\" not in lic)\n",
    "        )\n",
    "    ):\n",
    "        return \"Apertura total\"\n",
    "\n",
    "    # 5) Fallback coherente con Punto 1\n",
    "    if open_flag == 1:\n",
    "        return \"Apertura total\"\n",
    "\n",
    "    return \"Vacío legal\"\n",
    "\n",
    "\n",
    "df[\"license_bucket\"] = df.apply(license_bucket, axis=1)\n",
    "\n",
    "lic_counts = df[\"license_bucket\"].value_counts().reindex(\n",
    "    [\"Apertura total\",\"Restringida\",\"Vacío legal\"]\n",
    ").fillna(0).reset_index()\n",
    "lic_counts.columns = [\"Categoría\",\"Datasets\"]\n",
    "\n",
    "color_map_lic = {\n",
    "    \"Apertura total\": COLORS[\"abierto\"],\n",
    "    \"Restringida\": COLORS[\"restringido\"],\n",
    "    \"Vacío legal\": COLORS[\"vacio\"]\n",
    "}\n",
    "\n",
    "fig_license = px.bar(\n",
    "    lic_counts, x=\"Categoría\", y=\"Datasets\",\n",
    "    text=\"Datasets\",\n",
    "    title=\"Licenciamiento permitido (dimensión legal)\",\n",
    "    labels={\"Datasets\":\"Nº de datasets\"},\n",
    "    color=\"Categoría\",\n",
    "    color_discrete_map=color_map_lic\n",
    ")\n",
    "fig_license.update_traces(textposition=\"outside\", cliponaxis=False)\n",
    "polish(fig_license, height=420)\n",
    "\n",
    "caption_license = (\n",
    "    \"<b>Interpretación.</b> <i>Apertura total</i>: CC BY/CC Creative Commons y equivalentes. \"\n",
    "    \"<i>Restringida</i>: cláusula “No comercial” (CC BY-NC). \"\n",
    "    \"<i>Vacío legal</i>: licencia ausente o no definida.\"\n",
    ")\n",
    "\n",
    "# =============================================================\n",
    "# MÉTRICAS MADURAS POR PORTAL\n",
    "# =============================================================\n",
    "for col, default in [\n",
    "    (\"traceability_score\", np.nan),\n",
    "    (\"interoperability_semantics\", np.nan),\n",
    "    (\"interoperability_technical\", np.nan),\n",
    "    (\"accessibility_score\", np.nan),\n",
    "    (\"quality_score\", np.nan),\n",
    "\n",
    "    (\"traceable_origen\", 0),\n",
    "    (\"traceable_temporal\", 0),\n",
    "    (\"traceable_reutilizable\", 0),\n",
    "\n",
    "    (\"age_month_issued\", np.nan),\n",
    "    (\"age_months_modified\", np.nan),\n",
    "\n",
    "    (\"portal_supports_dcat_dcatap\", 0),\n",
    "    (\"api_type\", np.nan),\n",
    "    (\"uses_controlled_vocab\", 0),\n",
    "    (\"has_semantic_serialization\", 0),\n",
    "\n",
    "    (\"license_open\", 0),\n",
    "    (\"has_open_format\", 0),\n",
    "\n",
    "    (\"portal_has_api_rest\", 0),\n",
    "    (\"has_allowed_format\", 0),\n",
    "    (\"license_present\", 0),\n",
    "    (\"download_url_present\", 0),\n",
    "\n",
    "    (\"has_data_dictionary\", 0),\n",
    "    (\"description\", np.nan),\n",
    "\n",
    "    (\"update_frequency\", np.nan),\n",
    "\n",
    "    (\"portal_maturity\", np.nan),\n",
    "    (\"portal_maturity_level\", None),\n",
    "]:\n",
    "    if col not in df.columns:\n",
    "        df[col] = default\n",
    "\n",
    "# auxiliares\n",
    "df[\"_api_type_present\"] = df[\"api_type\"].notna().astype(int)\n",
    "df[\"_description_present\"] = df[\"description\"].astype(str).str.strip().replace(\"nan\",\"\").ne(\"\").astype(int)\n",
    "\n",
    "# Si portal_maturity no viene, lo calculamos como en Punto 3\n",
    "df[\"portal_maturity\"] = pd.to_numeric(df[\"portal_maturity\"], errors=\"coerce\")\n",
    "mask_missing = df[\"portal_maturity\"].isna()\n",
    "if mask_missing.any():\n",
    "    df.loc[mask_missing, \"portal_maturity\"] = (\n",
    "        pd.to_numeric(df.loc[mask_missing, \"accessibility_score\"], errors=\"coerce\") +\n",
    "        pd.to_numeric(df.loc[mask_missing, \"interoperability_semantics\"], errors=\"coerce\") +\n",
    "        pd.to_numeric(df.loc[mask_missing, \"interoperability_technical\"], errors=\"coerce\") +\n",
    "        pd.to_numeric(df.loc[mask_missing, \"traceability_score\"], errors=\"coerce\") +\n",
    "        pd.to_numeric(df.loc[mask_missing, \"quality_score\"], errors=\"coerce\")\n",
    "    ) / 5.0\n",
    "\n",
    "# =========================\n",
    "# Generar figs por portal\n",
    "# =========================\n",
    "portal_figs = {}  # portal -> list of (fig, caption)\n",
    "\n",
    "for portal_name, g in df.groupby(\"portal\"):\n",
    "    figs = []\n",
    "    g = g.copy()\n",
    "\n",
    "    # =========================================================\n",
    "    # 1) Trazabilidad temporal (USAR edades ya calculadas en Punto 3)\n",
    "    # =========================================================\n",
    "    g[\"age_month_issued\"] = pd.to_numeric(g[\"age_month_issued\"], errors=\"coerce\")\n",
    "    g[\"age_months_modified\"] = pd.to_numeric(g[\"age_months_modified\"], errors=\"coerce\")\n",
    "\n",
    "    fig_age_mod = px.histogram(\n",
    "        g.dropna(subset=[\"age_months_modified\"]),\n",
    "        x=\"age_months_modified\", nbins=25,\n",
    "        title=f\"Trazabilidad temporal – antigüedad desde última actualización (meses) | {portal_name}\",\n",
    "        labels={\"age_months_modified\":\"Meses\", \"count\":\"Nº de datasets\"}\n",
    "    )\n",
    "    fig_age_mod.update_yaxes(title_text=\"Nº de datasets\")\n",
    "    figs.append((polish(fig_age_mod, height=420),\n",
    "                 \"<b>Interpretación.</b> Antigüedad en meses desde <i>modified</i>, calculada en Punto 3 como \"\n",
    "                 \"<i>age_months_modified</i> (referencia: fecha del sistema).\"))\n",
    "\n",
    "    fig_age_iss = px.histogram(\n",
    "        g.dropna(subset=[\"age_month_issued\"]),\n",
    "        x=\"age_month_issued\", nbins=25,\n",
    "        title=f\"Trazabilidad temporal – antigüedad desde publicación (meses) | {portal_name}\",\n",
    "        labels={\"age_month_issued\":\"Meses\", \"count\":\"Nº de datasets\"}\n",
    "    )\n",
    "    fig_age_iss.update_yaxes(title_text=\"Nº de datasets\")\n",
    "    figs.append((polish(fig_age_iss, height=420),\n",
    "                 \"<b>Interpretación.</b> Antigüedad en meses desde <i>issued</i>, calculada en Punto 3 como \"\n",
    "                 \"<i>age_month_issued</i>.\"))\n",
    "\n",
    "    # =========================================================\n",
    "    # 2) Traceability – componentes (conteo) + desglose agregado\n",
    "    # =========================================================\n",
    "    n = len(g)\n",
    "    origin_count   = int((pd.to_numeric(g[\"traceable_origen\"], errors=\"coerce\").fillna(0) == 1).sum())\n",
    "    temporal_count = int((pd.to_numeric(g[\"traceable_temporal\"], errors=\"coerce\").fillna(0) == 1).sum())\n",
    "    doi_count      = int((pd.to_numeric(g[\"traceable_reutilizable\"], errors=\"coerce\").fillna(0) == 1).sum())\n",
    "\n",
    "    fig_trace_comp_count = bar_components_count(\n",
    "        [\"Origen\", \"Temporal\", \"Reutilizable (DOI)\"],\n",
    "        [origin_count, temporal_count, doi_count],\n",
    "        f\"Traceability – componentes (conteo de datasets) | {portal_name}\"\n",
    "    )\n",
    "    figs.append((fig_trace_comp_count,\n",
    "                 \"<b>Interpretación.</b> Conteo de datasets que cumplen cada componente: \"\n",
    "                 \"<i>origen</i> (publisher+url+identifier), <i>temporal</i> (issued+modified+update_frequency) y \"\n",
    "                 \"<i>reutilizable</i> (DOI).\"))\n",
    "\n",
    "    origin_pct   = origin_count / n * 100 if n else 0\n",
    "    temporal_pct = temporal_count / n * 100 if n else 0\n",
    "    doi_pct      = doi_count / n * 100 if n else 0\n",
    "\n",
    "    fig_trace_break = stacked_breakdown(\n",
    "        [\"Origen\", \"Temporal\", \"DOI/Reutilizable\"],\n",
    "        [origin_pct, temporal_pct, doi_pct],\n",
    "        f\"Traceability – desglose agregado (normalizado a 100) | {portal_name}\"\n",
    "    )\n",
    "    figs.append((fig_trace_break,\n",
    "                 \"<b>Interpretación.</b> Lectura agregada y comparable: muestra el peso relativo de cada componente. \"\n",
    "                 \"Si <i>DOI</i>=0, la trazabilidad máxima observable queda limitada.\"))\n",
    "\n",
    "    # =========================================================\n",
    "    # 3) Update frequency (vacíos -> No definido) con conteo + %\n",
    "    # =========================================================\n",
    "    uf = g[\"update_frequency\"].astype(str).str.strip()\n",
    "    uf = uf.replace([\"\", \"nan\", \"NaN\", \"None\"], np.nan)\n",
    "    uf = uf.fillna(\"No definido\")\n",
    "\n",
    "    uf = uf.str.lower().replace({\n",
    "        \"mensual\": \"monthly\",\n",
    "        \"semanal\": \"weekly\",\n",
    "        \"diaria\": \"daily\",\n",
    "        \"anual\": \"annual\",\n",
    "        \"trimestral\": \"quarterly\",\n",
    "        \"semestral\": \"semiannual\",\n",
    "    })\n",
    "\n",
    "    freq_counts = uf.value_counts().reset_index()\n",
    "    freq_counts.columns = [\"Frecuencia\", \"Datasets\"]\n",
    "    freq_counts[\"Porcentaje\"] = (freq_counts[\"Datasets\"] / len(g) * 100).round(1)\n",
    "    freq_counts[\"Etiqueta\"] = freq_counts.apply(lambda r: f\"{int(r['Datasets'])} ({r['Porcentaje']}%)\", axis=1)\n",
    "\n",
    "    fig_update_freq = px.bar(\n",
    "        freq_counts,\n",
    "        x=\"Frecuencia\", y=\"Datasets\",\n",
    "        text=\"Etiqueta\",\n",
    "        title=f\"Frecuencia de actualización declarada (update_frequency) | {portal_name}\",\n",
    "        labels={\"Datasets\": \"Nº de datasets\"}\n",
    "    )\n",
    "    fig_update_freq.update_traces(textposition=\"outside\", cliponaxis=False)\n",
    "    fig_update_freq.update_layout(xaxis_tickangle=-25)\n",
    "    fig_update_freq.update_yaxes(title_text=\"Nº de datasets\")\n",
    "\n",
    "    figs.append((polish(fig_update_freq, height=460),\n",
    "                 \"<b>Interpretación.</b> Frecuencia tomada directamente del Excel (columna <i>update_frequency</i>, Punto 3). \"\n",
    "                 \"Los valores vacíos se agrupan como <i>No definido</i>. La etiqueta muestra conteo y porcentaje.\"))\n",
    "\n",
    "    # =========================================================\n",
    "    # 4) Traceability_score -> barras por niveles (0/33/66/100)\n",
    "    # =========================================================\n",
    "    fig_trace_score_levels = traceability_score_bars(g, portal_name)\n",
    "    figs.append((polish(fig_trace_score_levels, height=420),\n",
    "                 \"<b>Interpretación.</b> Gráfico construido desde la columna <i>traceability_score</i> (Excel, Punto 3). \"\n",
    "                 \"Se calcula como <i>((traceable_origen + traceable_temporal + traceable_reutilizable)/3)*100</i>, \"\n",
    "                 \"por eso sus niveles esperados son 0/33/66/100.\"))\n",
    "\n",
    "    # =========================================================\n",
    "    # 5) Interoperabilidad semántica (dist + comp % + desglose)\n",
    "    # =========================================================\n",
    "    figs.append((hist_score(g, \"interoperability_semantics\",\n",
    "                            f\"Interoperabilidad semántica (0–100) – distribución | {portal_name}\"),\n",
    "                 \"<b>Interpretación.</b> Score (0–100) basado en: DCAT/DCAT-AP, presencia de api_type, vocabulario controlado y serialización semántica.\"))\n",
    "\n",
    "    dcat_pct  = float((pd.to_numeric(g[\"portal_supports_dcat_dcatap\"], errors=\"coerce\").fillna(0) == 1).mean() * 100)\n",
    "    api_pct   = float((pd.to_numeric(g[\"_api_type_present\"], errors=\"coerce\").fillna(0) == 1).mean() * 100)\n",
    "    vocab_pct = float((pd.to_numeric(g[\"uses_controlled_vocab\"], errors=\"coerce\").fillna(0) == 1).mean() * 100)\n",
    "    ser_pct   = float((pd.to_numeric(g[\"has_semantic_serialization\"], errors=\"coerce\").fillna(0) == 1).mean() * 100)\n",
    "\n",
    "    figs.append((bar_components_pct(\n",
    "        [\"DCAT/DCAT-AP\", \"API type presente\", \"Vocabulario controlado\", \"Serialización semántica\"],\n",
    "        [dcat_pct, api_pct, vocab_pct, ser_pct],\n",
    "        f\"Interoperabilidad semántica – componentes (% datasets) | {portal_name}\"\n",
    "    ), \"<b>Interpretación.</b> Porcentaje de datasets que evidencian cada componente semántico.\"))\n",
    "\n",
    "    figs.append((stacked_breakdown(\n",
    "        [\"DCAT/DCAT-AP\", \"API type presente\", \"Vocabulario controlado\", \"Serialización semántica\"],\n",
    "        [dcat_pct, api_pct, vocab_pct, ser_pct],\n",
    "        f\"Interoperabilidad semántica – desglose agregado (normalizado a 100) | {portal_name}\"\n",
    "    ), \"<b>Interpretación.</b> Peso relativo de cada componente en la dimensión semántica (normalizado).\" ))\n",
    "\n",
    "    # =========================================================\n",
    "    # 6) Interoperabilidad técnica (dist + comp % + desglose)\n",
    "    # =========================================================\n",
    "    figs.append((hist_score(g, \"interoperability_technical\",\n",
    "                            f\"Interoperabilidad técnica (0–100) – distribución | {portal_name}\"),\n",
    "                 \"<b>Interpretación.</b> Score (0–100) basado en licencia abierta y presencia de formato abierto.\"))\n",
    "\n",
    "    lic_open_pct = float((pd.to_numeric(g[\"license_open\"], errors=\"coerce\").fillna(0) == 1).mean() * 100)\n",
    "    fmt_open_pct = float((pd.to_numeric(g[\"has_open_format\"], errors=\"coerce\").fillna(0) == 1).mean() * 100)\n",
    "\n",
    "    figs.append((bar_components_pct(\n",
    "        [\"Licencia abierta\", \"Formato abierto\"],\n",
    "        [lic_open_pct, fmt_open_pct],\n",
    "        f\"Interoperabilidad técnica – componentes (% datasets) | {portal_name}\"\n",
    "    ), \"<b>Interpretación.</b> Cumplimiento técnico desagregado: licencias y formatos abiertos.\"))\n",
    "\n",
    "    figs.append((stacked_breakdown(\n",
    "        [\"Licencia abierta\", \"Formato abierto\"],\n",
    "        [lic_open_pct, fmt_open_pct],\n",
    "        f\"Interoperabilidad técnica – desglose agregado (normalizado a 100) | {portal_name}\"\n",
    "    ), \"<b>Interpretación.</b> Peso relativo de licencia vs formato (normalizado).\" ))\n",
    "\n",
    "    # =========================================================\n",
    "    # 7) Accesibilidad (dist + comp % + desglose)\n",
    "    # =========================================================\n",
    "    figs.append((hist_score(g, \"accessibility_score\",\n",
    "                            f\"Accesibilidad (0–100) – distribución | {portal_name}\"),\n",
    "                 \"<b>Interpretación.</b> Accesibilidad medida por API REST, formato permitido, licencia presente y URL de descarga.\"))\n",
    "\n",
    "    api_rest_pct  = float((pd.to_numeric(g[\"portal_has_api_rest\"], errors=\"coerce\").fillna(0) == 1).mean() * 100)\n",
    "    allowed_pct   = float((pd.to_numeric(g[\"has_allowed_format\"], errors=\"coerce\").fillna(0) == 1).mean() * 100)\n",
    "    lic_pres_pct  = float((pd.to_numeric(g[\"license_present\"], errors=\"coerce\").fillna(0) == 1).mean() * 100)\n",
    "    dl_pct        = float((pd.to_numeric(g[\"download_url_present\"], errors=\"coerce\").fillna(0) == 1).mean() * 100)\n",
    "\n",
    "    figs.append((bar_components_pct(\n",
    "        [\"API REST\", \"Formato permitido\", \"Licencia presente\", \"URL descarga\"],\n",
    "        [api_rest_pct, allowed_pct, lic_pres_pct, dl_pct],\n",
    "        f\"Accesibilidad – componentes (% datasets) | {portal_name}\"\n",
    "    ), \"<b>Interpretación.</b> Porcentaje de datasets que soportan cada condición de accesibilidad.\"))\n",
    "\n",
    "    figs.append((stacked_breakdown(\n",
    "        [\"API REST\", \"Formato permitido\", \"Licencia presente\", \"URL descarga\"],\n",
    "        [api_rest_pct, allowed_pct, lic_pres_pct, dl_pct],\n",
    "        f\"Accesibilidad – desglose agregado (normalizado a 100) | {portal_name}\"\n",
    "    ), \"<b>Interpretación.</b> Peso relativo de cada componente de accesibilidad.\"))\n",
    "\n",
    "    # =========================================================\n",
    "    # 8) Calidad (dist + componentes CONTEO + desglose)\n",
    "    # =========================================================\n",
    "    figs.append((hist_score(g, \"quality_score\",\n",
    "                            f\"Calidad (0–100) – distribución | {portal_name}\"),\n",
    "                 \"<b>Interpretación.</b> Calidad medida por diccionario de datos y presencia de descripción.\"))\n",
    "\n",
    "    dict_count = int((pd.to_numeric(g[\"has_data_dictionary\"], errors=\"coerce\").fillna(0) == 1).sum())\n",
    "    desc_count = int((pd.to_numeric(g[\"_description_present\"], errors=\"coerce\").fillna(0) == 1).sum())\n",
    "\n",
    "    fig_q_comp_count = bar_components_count(\n",
    "        [\"Diccionario de datos\", \"Descripción presente\"],\n",
    "        [dict_count, desc_count],\n",
    "        f\"Calidad – componentes (conteo de datasets) | {portal_name}\"\n",
    "    )\n",
    "    figs.append((fig_q_comp_count,\n",
    "                 \"<b>Interpretación.</b> Conteo de datasets con diccionario de datos y con descripción disponible.\"))\n",
    "\n",
    "    dict_pct = dict_count / n * 100 if n else 0\n",
    "    desc_pct = desc_count / n * 100 if n else 0\n",
    "\n",
    "    figs.append((stacked_breakdown(\n",
    "        [\"Diccionario de datos\", \"Descripción presente\"],\n",
    "        [dict_pct, desc_pct],\n",
    "        f\"Calidad – desglose agregado (normalizado a 100) | {portal_name}\"\n",
    "    ), \"<b>Interpretación.</b> Peso relativo de diccionario vs descripción (normalizado).\" ))\n",
    "\n",
    "    # =========================================================\n",
    "    # 9) Scorecard e Índice global + niveles (conteo + %)\n",
    "    # =========================================================\n",
    "    m = {\n",
    "        \"accessibility_score\": float(pd.to_numeric(g[\"accessibility_score\"], errors=\"coerce\").mean()),\n",
    "        \"interoperability_semantics\": float(pd.to_numeric(g[\"interoperability_semantics\"], errors=\"coerce\").mean()),\n",
    "        \"interoperability_technical\": float(pd.to_numeric(g[\"interoperability_technical\"], errors=\"coerce\").mean()),\n",
    "        \"traceability_score\": float(pd.to_numeric(g[\"traceability_score\"], errors=\"coerce\").mean()),\n",
    "        \"quality_score\": float(pd.to_numeric(g[\"quality_score\"], errors=\"coerce\").mean()),\n",
    "        \"Índice global (promedio 5 scores)\": float(pd.to_numeric(g[\"portal_maturity\"], errors=\"coerce\").mean()),\n",
    "    }\n",
    "\n",
    "    figs.append((scorecard(m, f\"Scorecard de madurez (promedios 0–100) | {portal_name}\"),\n",
    "                 \"<b>Interpretación.</b> El <i>Índice global</i> (<i>portal_maturity</i>) es el promedio de 5 scores: \"\n",
    "                 \"<i>accessibility_score</i>, <i>interoperability_semantics</i>, <i>interoperability_technical</i>, \"\n",
    "                 \"<i>traceability_score</i> y <i>quality_score</i>.\"))\n",
    "\n",
    "    if \"portal_maturity_level\" in g.columns and g[\"portal_maturity_level\"].notna().any():\n",
    "        levels = g[\"portal_maturity_level\"].astype(str)\n",
    "    else:\n",
    "        levels = pd.cut(\n",
    "            pd.to_numeric(g[\"portal_maturity\"], errors=\"coerce\"),\n",
    "            bins=[-0.1, 40, 70, 100],\n",
    "            labels=[\"bajo\", \"medio\", \"alto\"]\n",
    "        ).astype(str)\n",
    "\n",
    "    vc = levels.value_counts(dropna=False)\n",
    "    total_n = int(len(g))\n",
    "\n",
    "    level_df = pd.DataFrame({\n",
    "        \"Nivel\": [\"bajo\", \"medio\", \"alto\"],\n",
    "        \"Datasets\": [int(vc.get(\"bajo\", 0)), int(vc.get(\"medio\", 0)), int(vc.get(\"alto\", 0))]\n",
    "    })\n",
    "    level_df[\"Porcentaje\"] = (level_df[\"Datasets\"] / (total_n if total_n else 1) * 100).round(1)\n",
    "    level_df[\"Etiqueta\"] = level_df.apply(lambda r: f\"{r['Datasets']} ({r['Porcentaje']}%)\", axis=1)\n",
    "\n",
    "    fig_levels = px.bar(\n",
    "        level_df, x=\"Nivel\", y=\"Datasets\", text=\"Etiqueta\",\n",
    "        title=f\"Distribución de niveles de madurez (índice global) | {portal_name}\",\n",
    "        labels={\"Datasets\": \"Nº de datasets\"},\n",
    "        color=\"Nivel\",\n",
    "        color_discrete_map={\"bajo\": \"#d62728\", \"medio\": \"#ff7f0e\", \"alto\": \"#2ca02c\"}\n",
    "    )\n",
    "    fig_levels.update_traces(textposition=\"outside\", cliponaxis=False)\n",
    "    fig_levels.update_yaxes(title_text=\"Nº de datasets\")\n",
    "\n",
    "    figs.append((polish(fig_levels, height=420),\n",
    "                 f\"<b>Interpretación.</b> Nivel calculado desde <i>portal_maturity</i> (Excel, Punto 3). \"\n",
    "                 f\"Se reporta conteo y porcentaje sobre el total del portal: <b>N={total_n}</b>. \"\n",
    "                 \"Cortes: bajo ≤ 40, medio (40–70], alto > 70.\"))\n",
    "\n",
    "    portal_figs[portal_name] = figs\n",
    "\n",
    "# =============================================================\n",
    "# Render HTML con “captions” fuera del gráfico \n",
    "# =============================================================\n",
    "def fig_html(fig):\n",
    "    return fig.to_html(full_html=False, include_plotlyjs=False)\n",
    "\n",
    "def card(fig, caption):\n",
    "    return f\"\"\"\n",
    "    <div class=\"card\">\n",
    "      {fig_html(fig)}\n",
    "      <div class=\"caption\">{caption}</div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "\n",
    "cards_html = []\n",
    "cards_html.append(card(fig_fmt_types, caption_fmt_types))\n",
    "cards_html.append(card(fig_fmt_pct, caption_fmt_pct))\n",
    "cards_html.append(card(fig_license, caption_license))\n",
    "\n",
    "for portal_name, figs in portal_figs.items():\n",
    "    cards_html.append(f\"<h2 style='margin-top:26px;'>Portal: {portal_name}</h2>\")\n",
    "    for fig, cap in figs:\n",
    "        cards_html.append(card(fig, cap))\n",
    "\n",
    "html = f\"\"\"\n",
    "<!doctype html>\n",
    "<html lang=\"es\">\n",
    "<head>\n",
    "  <meta charset=\"utf-8\"/>\n",
    "  <title>Dashboard – Madurez Ecosistema Open Data</title>\n",
    "  <script src=\"https://cdn.plot.ly/plotly-2.27.0.min.js\"></script>\n",
    "  <style>\n",
    "    body {{ font-family: Arial, sans-serif; margin: 22px; }}\n",
    "    h1 {{ margin-bottom: 6px; }}\n",
    "    h2 {{ margin-bottom: 8px; }}\n",
    "    .sub {{ color: #555; margin-bottom: 18px; }}\n",
    "    .grid2 {{ display: grid; grid-template-columns: 1fr; gap: 18px; }}\n",
    "    .card {{\n",
    "      border: 1px solid #ddd; border-radius: 12px; padding: 12px;\n",
    "      background: #fff;\n",
    "      margin-bottom: 14px;\n",
    "    }}\n",
    "    .caption {{\n",
    "      margin-top: 10px;\n",
    "      font-size: 13.5px;\n",
    "      color: #333;\n",
    "      line-height: 1.35;\n",
    "      background: #fafafa;\n",
    "      border: 1px solid #eee;\n",
    "      border-radius: 10px;\n",
    "      padding: 10px 12px;\n",
    "    }}\n",
    "    @media (min-width: 1100px) {{\n",
    "      .grid2 {{ grid-template-columns: 1fr 1fr; }}\n",
    "    }}\n",
    "  </style>\n",
    "</head>\n",
    "<body>\n",
    "  <h1>Dashboard – Análisis de madurez del ecosistema de datos abiertos</h1>\n",
    "  <div class=\"sub\">Visualizaciones interactivas basadas en los metadatos procesados (Punto 3 – V9 LIMPIO).</div>\n",
    "\n",
    "  <div class=\"grid2\">\n",
    "    {cards_html[0]}\n",
    "    {cards_html[1]}\n",
    "  </div>\n",
    "\n",
    "  <div class=\"grid2\">\n",
    "    {cards_html[2]}\n",
    "  </div>\n",
    "\n",
    "  <div>\n",
    "    {\"\".join(cards_html[3:])}\n",
    "  </div>\n",
    "\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "Path(OUT_HTML).write_text(html, encoding=\"utf-8\")\n",
    "print(\" Dashboard PRO generado:\", OUT_HTML)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
